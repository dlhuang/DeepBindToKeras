{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def convert_model(file_name, input_len, window_size=0):\n",
    "    \n",
    "    data = [x.rstrip() for x in open(file_name).read().split(\"\\n\")]\n",
    "    \n",
    "    reverse_complement = int(data[1].split(\" = \")[1])\n",
    "    num_detectors = int(data[2].split(\" = \")[1])\n",
    "    detector_len = int(data[3].split(\" = \")[1])\n",
    "    has_avg_pooling = int(data[4].split(\" = \")[1])\n",
    "    num_hidden = int(data[5].split(\" = \")[1])\n",
    "    \n",
    "    if (window_size < 1):\n",
    "        window_size = (int)(detector_len*1.5) #copying deepbind code\n",
    "    if (window_size > input_len):\n",
    "        window_size = input_len\n",
    "\n",
    "    detectors = (np.array(\n",
    "        [float(x) for x in data[6].split(\" = \")[1].split(\",\")])\n",
    "        .reshape(detector_len, 4, num_detectors))\n",
    "    biases = np.array([float(x) for x in data[7].split(\" = \")[1].split(\",\")])\n",
    "    weights1 = np.array([float(x) for x in data[8].split(\" = \")[1].split(\",\")]).reshape(\n",
    "                        num_detectors*(2 if has_avg_pooling else 1),\n",
    "                        (1 if num_hidden==0 else num_hidden))\n",
    "    if (has_avg_pooling > 0):\n",
    "        #in the orignal deepbind model, these weights are interleaved.\n",
    "        #what a nightmare.\n",
    "        weights1 = weights1.reshape((num_detectors,2,-1))\n",
    "        new_weights1 = np.zeros((2*num_detectors, weights1.shape[-1]))\n",
    "        new_weights1[:num_detectors, :] = weights1[:,0,:]\n",
    "        new_weights1[num_detectors:, :] = weights1[:,1,:]\n",
    "        weights1 = new_weights1\n",
    "    biases1 = np.array([float(x) for x in data[9].split(\" = \")[1].split(\",\")]).reshape(\n",
    "                        (1 if num_hidden==0 else num_hidden))\n",
    "    if (num_hidden > 0):\n",
    "        #print(\"Model has a hidden layer\")\n",
    "        weights2 = np.array([float(x) for x in data[10].split(\" = \")[1].split(\",\")]).reshape(\n",
    "                        num_hidden,1)\n",
    "        biases2 = np.array([float(x) for x in data[11].split(\" = \")[1].split(\",\")]).reshape(\n",
    "                        1)\n",
    "    \n",
    "    \n",
    "    def seq_padding(x):\n",
    "        return tf.pad(x,\n",
    "                [[0, 0],\n",
    "                 [detector_len-1, detector_len-1],\n",
    "                 [0, 0]],\n",
    "                mode='CONSTANT',\n",
    "                name=None,\n",
    "                constant_values=0.25)\n",
    "\n",
    "    \n",
    "    input_tensor = keras.layers.Input(shape=(None,4))\n",
    "    padding_out_fwd = keras.layers.Lambda(seq_padding)(input_tensor)\n",
    "    conv_layer = keras.layers.Conv1D(filters=num_detectors,\n",
    "                                  kernel_size=detector_len,\n",
    "                                  activation=\"relu\")\n",
    "    conv_out_fwd = conv_layer(padding_out_fwd)\n",
    "    pool_out_fwd = keras.layers.MaxPooling1D(pool_size=(window_size+detector_len-1),\n",
    "                                             strides=1)(conv_out_fwd)\n",
    "    if (has_avg_pooling > 0):\n",
    "        #print(\"Model has average pooling\")\n",
    "        gap_out_fwd = keras.layers.AveragePooling1D(pool_size=(window_size+detector_len-1),\n",
    "                                                     strides=1)(conv_out_fwd)\n",
    "        pool_out_fwd = keras.layers.Concatenate(axis=-1)([pool_out_fwd, gap_out_fwd])        \n",
    "    dense1_layer = keras.layers.Dense((1 if num_hidden==0 else num_hidden))\n",
    "    dense1_out_fwd = keras.layers.TimeDistributed(dense1_layer)(pool_out_fwd)\n",
    "    if (num_hidden > 0):\n",
    "        dense1_out_fwd = keras.layers.Activation(\"relu\")(dense1_out_fwd)\n",
    "        dense2_layer = keras.layers.Dense(1)\n",
    "        dense2_out_fwd = keras.layers.TimeDistributed(dense2_layer)(dense1_out_fwd)\n",
    "    \n",
    "    if (reverse_complement > 0):\n",
    "        #print(\"Model has reverse complementation\")\n",
    "        padding_out_rev = keras.layers.Lambda(lambda x: x[:,::-1,::-1])(padding_out_fwd)\n",
    "        conv_out_rev = conv_layer(padding_out_rev)\n",
    "        pool_out_rev = keras.layers.MaxPooling1D(pool_size=(window_size+detector_len-1),\n",
    "                                             strides=1)(conv_out_rev)\n",
    "        if (has_avg_pooling > 0):\n",
    "            #print(\"Model has average pooling\")\n",
    "            gap_out_rev = keras.layers.AveragePooling1D(pool_size=(window_size+detector_len-1),\n",
    "                                                     strides=1)(conv_out_rev)\n",
    "            pool_out_rev = keras.layers.Concatenate(axis=-1)([pool_out_rev, gap_out_rev])\n",
    "        dense1_out_rev = keras.layers.TimeDistributed(dense1_layer)(pool_out_rev)\n",
    "        if (num_hidden > 0):\n",
    "            dense1_out_rev = keras.layers.Activation(\"relu\")(dense1_out_rev)\n",
    "            dense2_out_rev = keras.layers.TimeDistributed(dense2_layer)(dense1_out_rev)\n",
    "    \n",
    "    cross_seq_max = keras.layers.Lambda(lambda x: tf.reduce_max(x,axis=1)[:,0],\n",
    "                                        output_shape=lambda x: (None,1))\n",
    "    \n",
    "    if (reverse_complement > 0):\n",
    "        if (num_hidden > 0):\n",
    "            max_fwd = cross_seq_max(dense2_out_fwd)\n",
    "            max_rev = cross_seq_max(dense2_out_rev)\n",
    "            output = keras.layers.Maximum()([max_fwd, max_rev])\n",
    "        else:\n",
    "            max_fwd = cross_seq_max(dense1_out_fwd)\n",
    "            max_rev = cross_seq_max(dense1_out_rev)\n",
    "            output = keras.layers.Maximum()([max_fwd, max_rev])\n",
    "    else:\n",
    "        if (num_hidden > 0):\n",
    "            output = cross_seq_max(dense2_out_fwd)\n",
    "        else:\n",
    "            output = cross_seq_max(dense1_out_fwd)\n",
    "        \n",
    "        \n",
    "    model = keras.models.Model(inputs = [input_tensor],\n",
    "                               outputs = [output])\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    conv_layer.set_weights([detectors, biases])\n",
    "    dense1_layer.set_weights([weights1, biases1])\n",
    "    if (num_hidden > 0):\n",
    "        dense2_layer.set_weights([weights2, biases2])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def onehot_encode_sequences(sequences):\n",
    "    onehot = []\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3, 'U': 3}\n",
    "    for sequence in sequences:\n",
    "        arr = np.zeros((len(sequence), 4)).astype(\"float\")\n",
    "        for (i, letter) in enumerate(sequence):\n",
    "            arr[i, mapping[letter]] = 1.0\n",
    "        onehot.append(arr)\n",
    "    return onehot\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('On model', 'deepbind_db/params/D00210.001.txt')\n",
      "7.0591083\n",
      "-0.17260918\n",
      "-0.14068288\n",
      "-0.1749849\n",
      "('On model', 'deepbind_db/params/D00120.001.txt')\n",
      "-0.18721244\n",
      "4.2956724\n",
      "0.18129458\n",
      "-0.15252134\n",
      "('On model', 'deepbind_db/params/D00410.003.txt')\n",
      "-0.64944744\n",
      "0.666795\n",
      "5.8853483\n",
      "-0.37969446\n",
      "('On model', 'deepbind_db/params/D00328.003.txt')\n",
      "-0.026180174\n",
      "-0.91077334\n",
      "-0.026180174\n",
      "17.682623\n"
     ]
    }
   ],
   "source": [
    "#Test the conversion on the example sequences in example.seq and compare to\n",
    "#the expected output\n",
    "\n",
    "for file_name in [\n",
    "    \n",
    "    \"deepbind_db/params/D00210.001.txt\",\n",
    "    \"deepbind_db/params/D00120.001.txt\",  \n",
    "    \"deepbind_db/params/D00410.003.txt\",\n",
    "    \"deepbind_db/params/D00328.003.txt\",\n",
    "\n",
    "]:\n",
    "    print(\"On model\", file_name)\n",
    "\n",
    "    #these sequences are taken from the example.seq\n",
    "    #% deepbind example.ids < example.seq\n",
    "    #D00210.001   D00120.001   D00410.003   D00328.003\n",
    "    #7.451420    -0.166146    -0.408751    -0.026180\n",
    "    #-0.155398     4.113817     0.516956    -0.248167\n",
    "    #-0.140683     0.181295     5.885349    -0.026180\n",
    "    #-0.174985    -0.152521    -0.379695    17.682623\n",
    "    \n",
    "    onehot_sequences = onehot_encode_sequences(\n",
    "        ['AGGUAAUAAUUUGCAUGAAAUAACUUGGAGAGGAUAGC',\n",
    "         'AGACAGAGCUUCCAUCAGCGCUAGCAGCAGAGACCAUU',\n",
    "         'GAGGTTACGCGGCAAGATAA',\n",
    "         'TACCACTAGGGGGCGCCACC'])\n",
    "\n",
    "    model = convert_model(file_name = file_name, input_len=38)\n",
    "    print(\"\\n\".join(str(x) for x\n",
    "                    in model.predict(np.array(onehot_sequences[0:2])[:,:,:])))\n",
    "\n",
    "    model = convert_model(file_name = file_name, input_len=20)\n",
    "    print(\"\\n\".join(str(x) for x\n",
    "                    in model.predict(np.array(onehot_sequences[2:])[:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
